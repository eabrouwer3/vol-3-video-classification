{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2     # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   # for resizing images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "from scipy import stats as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      video_name\n",
       "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1\n",
       "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1\n",
       "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1\n",
       "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1\n",
       "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the .txt file which have names of training videos\n",
    "f = open(\"trainlist01.txt\", \"r\")\n",
    "temp = f.read()\n",
    "videos = temp.split('\\n')\n",
    "\n",
    "# creating a dataframe having video names\n",
    "train = pd.DataFrame()\n",
    "train['video_name'] = videos\n",
    "train = train[:-1]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Archery/v_Archery_g04_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Archery/v_Archery_g04_c02.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Archery/v_Archery_g04_c03.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Archery/v_Archery_g04_c04.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Archery/v_Archery_g04_c05.avi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     video_name\n",
       "0   ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi\n",
       "1   ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi\n",
       "2   ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi\n",
       "3   ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi\n",
       "4   ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi\n",
       "..                                          ...\n",
       "95                Archery/v_Archery_g04_c01.avi\n",
       "96                Archery/v_Archery_g04_c02.avi\n",
       "97                Archery/v_Archery_g04_c03.avi\n",
       "98                Archery/v_Archery_g04_c04.avi\n",
       "99                Archery/v_Archery_g04_c05.avi\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the .txt file which have names of test videos\n",
    "f = open(\"testlist01.txt\", \"r\")\n",
    "temp = f.read()\n",
    "videos = temp.split('\\n')\n",
    "\n",
    "# creating a dataframe having video names\n",
    "test = pd.DataFrame()\n",
    "test['video_name'] = videos\n",
    "test = test[:-1]\n",
    "test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tags for training videos\n",
    "train_video_tag = []\n",
    "for i in range(train.shape[0]):\n",
    "    train_video_tag.append(train['video_name'][i].split('/')[0])\n",
    "    \n",
    "train['tag'] = train_video_tag\n",
    "\n",
    "# creating tags for test videos\n",
    "test_video_tag = []\n",
    "for i in range(test.shape[0]):\n",
    "    test_video_tag.append(test['video_name'][i].split('/')[0])\n",
    "    \n",
    "test['tag'] = test_video_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9537/9537 [01:58<00:00, 80.35it/s] \n"
     ]
    }
   ],
   "source": [
    "# storing the frames from training videos\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    count = 0\n",
    "    videoFile = train['video_name'][i]\n",
    "    #print(videoFile)\n",
    "    cap = cv2.VideoCapture('UCF/'+videoFile.split(' ')[0].split('/')[1])   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    x=1\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if frameId%math.floor(frameRate) == 0:\n",
    "            # storing the frames in a new folder named train_1\n",
    "            filename ='train_1/' + videoFile.split('/')[1].split(' ')[0] +\"_frame%d.jpg\"%count;count+=1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10645/10645 [00:00<00:00, 522044.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# getting the names of all the images\n",
    "images = glob(\"train_1/*.jpg\")\n",
    "print(len(images))\n",
    "train_image = []\n",
    "train_class = []\n",
    "for i in tqdm(range(len(images))):\n",
    "    # creating the image name\n",
    "    train_image.append(images[i].split('/')[1])\n",
    "    # creating the class of image\n",
    "    train_class.append(images[i].split('/')[1].split('_')[1])\n",
    "    \n",
    "# storing the images and their class in a dataframe\n",
    "train_data = pd.DataFrame()\n",
    "train_data['image'] = train_image\n",
    "train_data['class'] = train_class\n",
    "\n",
    "# converting the dataframe into csv file \n",
    "train_data.to_csv('UCF/train_new.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v_Billiards_g24_c02.avi_frame4.jpg</td>\n",
       "      <td>Billiards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v_Billiards_g21_c06.avi_frame7.jpg</td>\n",
       "      <td>Billiards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_Biking_g23_c01.avi_frame14.jpg</td>\n",
       "      <td>Biking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v_BlowingCandles_g17_c03.avi_frame5.jpg</td>\n",
       "      <td>BlowingCandles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v_BodyWeightSquats_g15_c04.avi_frame3.jpg</td>\n",
       "      <td>BodyWeightSquats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image             class\n",
       "0         v_Billiards_g24_c02.avi_frame4.jpg         Billiards\n",
       "1         v_Billiards_g21_c06.avi_frame7.jpg         Billiards\n",
       "2           v_Biking_g23_c01.avi_frame14.jpg            Biking\n",
       "3    v_BlowingCandles_g17_c03.avi_frame5.jpg    BlowingCandles\n",
       "4  v_BodyWeightSquats_g15_c04.avi_frame3.jpg  BodyWeightSquats"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('UCF/train_new.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10645/10645 [00:37<00:00, 286.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10645, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('train_1/'+train['image'][i], target_size=(224,224,3))\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)\n",
    "    \n",
    "# converting the list to numpy array\n",
    "X = np.array(train_image)\n",
    "\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2129, 224, 224, 3)\n",
      "(8516, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8516, 7, 7, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2129, 7, 7, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_test = X_test.reshape(2129, 7*7*512)\n",
    "X_train = X_train.reshape(8516, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the pixel values\n",
    "max = X_train.max()\n",
    "X_train = X_train/max\n",
    "X_test = X_test/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8516, 25088)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of images\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(17, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8516, 25088)\n",
      "(8516, 17)\n",
      "(2129, 25088)\n",
      "(2129, 17)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "67/67 [==============================] - 18s 272ms/step - loss: 2.3976 - accuracy: 0.2295 - val_loss: 1.7693 - val_accuracy: 0.3776\n",
      "Epoch 2/200\n",
      "67/67 [==============================] - 21s 320ms/step - loss: 1.5791 - accuracy: 0.4617 - val_loss: 0.8701 - val_accuracy: 0.7529\n",
      "Epoch 3/200\n",
      "67/67 [==============================] - 18s 272ms/step - loss: 0.8561 - accuracy: 0.7125 - val_loss: 0.3303 - val_accuracy: 0.9220\n",
      "Epoch 4/200\n",
      "67/67 [==============================] - 19s 282ms/step - loss: 0.4371 - accuracy: 0.8562 - val_loss: 0.1339 - val_accuracy: 0.9667\n",
      "Epoch 5/200\n",
      "67/67 [==============================] - 16s 232ms/step - loss: 0.2591 - accuracy: 0.9209 - val_loss: 0.0811 - val_accuracy: 0.9765\n",
      "Epoch 6/200\n",
      "67/67 [==============================] - 16s 241ms/step - loss: 0.1786 - accuracy: 0.9462 - val_loss: 0.0645 - val_accuracy: 0.9822\n",
      "Epoch 7/200\n",
      "67/67 [==============================] - 15s 226ms/step - loss: 0.1330 - accuracy: 0.9602 - val_loss: 0.0715 - val_accuracy: 0.9822\n",
      "Epoch 8/200\n",
      "67/67 [==============================] - 18s 266ms/step - loss: 0.1282 - accuracy: 0.9624 - val_loss: 0.0609 - val_accuracy: 0.9878\n",
      "Epoch 9/200\n",
      "67/67 [==============================] - 16s 242ms/step - loss: 0.0955 - accuracy: 0.9717 - val_loss: 0.0416 - val_accuracy: 0.9887\n",
      "Epoch 10/200\n",
      "67/67 [==============================] - 16s 239ms/step - loss: 0.0878 - accuracy: 0.9730 - val_loss: 0.0413 - val_accuracy: 0.9887\n",
      "Epoch 11/200\n",
      "67/67 [==============================] - 17s 247ms/step - loss: 0.0742 - accuracy: 0.9789 - val_loss: 0.0393 - val_accuracy: 0.9906\n",
      "Epoch 12/200\n",
      "67/67 [==============================] - 14s 214ms/step - loss: 0.0845 - accuracy: 0.9777 - val_loss: 0.0465 - val_accuracy: 0.9878\n",
      "Epoch 13/200\n",
      "67/67 [==============================] - 15s 225ms/step - loss: 0.0647 - accuracy: 0.9816 - val_loss: 0.0354 - val_accuracy: 0.9911\n",
      "Epoch 14/200\n",
      "67/67 [==============================] - 14s 209ms/step - loss: 0.0673 - accuracy: 0.9825 - val_loss: 0.0391 - val_accuracy: 0.9920\n",
      "Epoch 15/200\n",
      "67/67 [==============================] - 16s 246ms/step - loss: 0.0723 - accuracy: 0.9806 - val_loss: 0.0553 - val_accuracy: 0.9864\n",
      "Epoch 16/200\n",
      "67/67 [==============================] - 16s 245ms/step - loss: 0.0731 - accuracy: 0.9782 - val_loss: 0.0499 - val_accuracy: 0.9868\n",
      "Epoch 17/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.0527 - accuracy: 0.9865 - val_loss: 0.0424 - val_accuracy: 0.9901\n",
      "Epoch 18/200\n",
      "67/67 [==============================] - 15s 225ms/step - loss: 0.0616 - accuracy: 0.9836 - val_loss: 0.0405 - val_accuracy: 0.9906\n",
      "Epoch 19/200\n",
      "67/67 [==============================] - 16s 233ms/step - loss: 0.0453 - accuracy: 0.9872 - val_loss: 0.0394 - val_accuracy: 0.9911\n",
      "Epoch 20/200\n",
      "67/67 [==============================] - 15s 231ms/step - loss: 0.0474 - accuracy: 0.9886 - val_loss: 0.0341 - val_accuracy: 0.9930\n",
      "Epoch 21/200\n",
      "67/67 [==============================] - 13s 196ms/step - loss: 0.0498 - accuracy: 0.9864 - val_loss: 0.0359 - val_accuracy: 0.9930\n",
      "Epoch 22/200\n",
      "67/67 [==============================] - 18s 263ms/step - loss: 0.0443 - accuracy: 0.9881 - val_loss: 0.0475 - val_accuracy: 0.9906\n",
      "Epoch 23/200\n",
      "67/67 [==============================] - 18s 262ms/step - loss: 0.0407 - accuracy: 0.9897 - val_loss: 0.0698 - val_accuracy: 0.9878\n",
      "Epoch 24/200\n",
      "67/67 [==============================] - 18s 272ms/step - loss: 0.0589 - accuracy: 0.9831 - val_loss: 0.0489 - val_accuracy: 0.9887\n",
      "Epoch 25/200\n",
      "67/67 [==============================] - 15s 221ms/step - loss: 0.0508 - accuracy: 0.9853 - val_loss: 0.0518 - val_accuracy: 0.9911\n",
      "Epoch 26/200\n",
      "67/67 [==============================] - 13s 190ms/step - loss: 0.0491 - accuracy: 0.9870 - val_loss: 0.0333 - val_accuracy: 0.9925\n",
      "Epoch 27/200\n",
      "67/67 [==============================] - 13s 190ms/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 0.0377 - val_accuracy: 0.9925\n",
      "Epoch 28/200\n",
      "67/67 [==============================] - 12s 181ms/step - loss: 0.0411 - accuracy: 0.9880 - val_loss: 0.0490 - val_accuracy: 0.9906\n",
      "Epoch 29/200\n",
      "67/67 [==============================] - 12s 182ms/step - loss: 0.0385 - accuracy: 0.9890 - val_loss: 0.0548 - val_accuracy: 0.9906\n",
      "Epoch 30/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0519 - accuracy: 0.9873 - val_loss: 0.0352 - val_accuracy: 0.9911\n",
      "Epoch 31/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0604 - accuracy: 0.9851 - val_loss: 0.0426 - val_accuracy: 0.9915\n",
      "Epoch 32/200\n",
      "67/67 [==============================] - 13s 191ms/step - loss: 0.0426 - accuracy: 0.9879 - val_loss: 0.0325 - val_accuracy: 0.9925\n",
      "Epoch 33/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0496 - accuracy: 0.9866 - val_loss: 0.0406 - val_accuracy: 0.9915\n",
      "Epoch 34/200\n",
      "67/67 [==============================] - 12s 182ms/step - loss: 0.0315 - accuracy: 0.9922 - val_loss: 0.0533 - val_accuracy: 0.9911\n",
      "Epoch 35/200\n",
      "67/67 [==============================] - 12s 186ms/step - loss: 0.0401 - accuracy: 0.9888 - val_loss: 0.0358 - val_accuracy: 0.9930\n",
      "Epoch 36/200\n",
      "67/67 [==============================] - 12s 182ms/step - loss: 0.0404 - accuracy: 0.9906 - val_loss: 0.0395 - val_accuracy: 0.9920\n",
      "Epoch 37/200\n",
      "67/67 [==============================] - 12s 182ms/step - loss: 0.0532 - accuracy: 0.9868 - val_loss: 0.0333 - val_accuracy: 0.9920\n",
      "Epoch 38/200\n",
      "67/67 [==============================] - 13s 194ms/step - loss: 0.0514 - accuracy: 0.9870 - val_loss: 0.0260 - val_accuracy: 0.9958\n",
      "Epoch 39/200\n",
      "67/67 [==============================] - 12s 182ms/step - loss: 0.0448 - accuracy: 0.9892 - val_loss: 0.0322 - val_accuracy: 0.9948\n",
      "Epoch 40/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0418 - accuracy: 0.9903 - val_loss: 0.0482 - val_accuracy: 0.9906\n",
      "Epoch 41/200\n",
      "67/67 [==============================] - 13s 193ms/step - loss: 0.0321 - accuracy: 0.9906 - val_loss: 0.0317 - val_accuracy: 0.9930\n",
      "Epoch 42/200\n",
      "67/67 [==============================] - 13s 192ms/step - loss: 0.0316 - accuracy: 0.9928 - val_loss: 0.0538 - val_accuracy: 0.9901\n",
      "Epoch 43/200\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 0.0427 - accuracy: 0.9903 - val_loss: 0.0414 - val_accuracy: 0.9920\n",
      "Epoch 44/200\n",
      "67/67 [==============================] - 13s 187ms/step - loss: 0.0277 - accuracy: 0.9927 - val_loss: 0.0399 - val_accuracy: 0.9920\n",
      "Epoch 45/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.0404 - val_accuracy: 0.9948\n",
      "Epoch 46/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0255 - accuracy: 0.9939 - val_loss: 0.0474 - val_accuracy: 0.9897\n",
      "Epoch 47/200\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 0.0160 - accuracy: 0.9955 - val_loss: 0.0309 - val_accuracy: 0.9944\n",
      "Epoch 48/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0338 - accuracy: 0.9919 - val_loss: 0.0387 - val_accuracy: 0.9934\n",
      "Epoch 49/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0328 - accuracy: 0.9919 - val_loss: 0.0492 - val_accuracy: 0.9915\n",
      "Epoch 50/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0339 - accuracy: 0.9899 - val_loss: 0.0372 - val_accuracy: 0.9934\n",
      "Epoch 51/200\n",
      "67/67 [==============================] - 13s 192ms/step - loss: 0.0271 - accuracy: 0.9938 - val_loss: 0.0330 - val_accuracy: 0.9953\n",
      "Epoch 52/200\n",
      "67/67 [==============================] - 14s 216ms/step - loss: 0.0325 - accuracy: 0.9920 - val_loss: 0.0539 - val_accuracy: 0.9906\n",
      "Epoch 53/200\n",
      "67/67 [==============================] - 13s 193ms/step - loss: 0.0328 - accuracy: 0.9917 - val_loss: 0.0345 - val_accuracy: 0.9934\n",
      "Epoch 54/200\n",
      "67/67 [==============================] - 13s 190ms/step - loss: 0.0226 - accuracy: 0.9935 - val_loss: 0.0366 - val_accuracy: 0.9953\n",
      "Epoch 55/200\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 0.0274 - accuracy: 0.9932 - val_loss: 0.0334 - val_accuracy: 0.9939\n",
      "Epoch 56/200\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 0.0580 - accuracy: 0.9872 - val_loss: 0.0424 - val_accuracy: 0.9906\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 12s 181ms/step - loss: 0.0299 - accuracy: 0.9931 - val_loss: 0.0506 - val_accuracy: 0.9930\n",
      "Epoch 58/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.0395 - val_accuracy: 0.9930\n",
      "Epoch 59/200\n",
      "67/67 [==============================] - 13s 189ms/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 0.0252 - val_accuracy: 0.9948\n",
      "Epoch 60/200\n",
      "67/67 [==============================] - 12s 181ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.0553 - val_accuracy: 0.9915\n",
      "Epoch 61/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0379 - accuracy: 0.9914 - val_loss: 0.0602 - val_accuracy: 0.9906\n",
      "Epoch 62/200\n",
      "67/67 [==============================] - 13s 187ms/step - loss: 0.0296 - accuracy: 0.9924 - val_loss: 0.0539 - val_accuracy: 0.9901\n",
      "Epoch 63/200\n",
      "67/67 [==============================] - 12s 182ms/step - loss: 0.0212 - accuracy: 0.9947 - val_loss: 0.0565 - val_accuracy: 0.9920\n",
      "Epoch 64/200\n",
      "67/67 [==============================] - 12s 182ms/step - loss: 0.0346 - accuracy: 0.9924 - val_loss: 0.0527 - val_accuracy: 0.9925\n",
      "Epoch 65/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0340 - accuracy: 0.9917 - val_loss: 0.0346 - val_accuracy: 0.9930\n",
      "Epoch 66/200\n",
      "67/67 [==============================] - 12s 181ms/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.0419 - val_accuracy: 0.9915\n",
      "Epoch 67/200\n",
      "67/67 [==============================] - 12s 182ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0438 - val_accuracy: 0.9944\n",
      "Epoch 68/200\n",
      "67/67 [==============================] - 13s 191ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 0.0420 - val_accuracy: 0.9925\n",
      "Epoch 69/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0332 - accuracy: 0.9924 - val_loss: 0.0361 - val_accuracy: 0.9930\n",
      "Epoch 70/200\n",
      "67/67 [==============================] - 14s 204ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.0469 - val_accuracy: 0.9915\n",
      "Epoch 71/200\n",
      "67/67 [==============================] - 14s 211ms/step - loss: 0.0293 - accuracy: 0.9934 - val_loss: 0.0374 - val_accuracy: 0.9911\n",
      "Epoch 72/200\n",
      "67/67 [==============================] - 13s 195ms/step - loss: 0.0296 - accuracy: 0.9933 - val_loss: 0.0461 - val_accuracy: 0.9911\n",
      "Epoch 73/200\n",
      "67/67 [==============================] - 12s 182ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: 0.0547 - val_accuracy: 0.9915\n",
      "Epoch 74/200\n",
      "67/67 [==============================] - 12s 182ms/step - loss: 0.0314 - accuracy: 0.9919 - val_loss: 0.0407 - val_accuracy: 0.9934\n",
      "Epoch 75/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0297 - accuracy: 0.9918 - val_loss: 0.0615 - val_accuracy: 0.9911\n",
      "Epoch 76/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0456 - accuracy: 0.9904 - val_loss: 0.0418 - val_accuracy: 0.9925\n",
      "Epoch 77/200\n",
      "67/67 [==============================] - 12s 181ms/step - loss: 0.0458 - accuracy: 0.9893 - val_loss: 0.0472 - val_accuracy: 0.9925\n",
      "Epoch 78/200\n",
      "67/67 [==============================] - 13s 187ms/step - loss: 0.0257 - accuracy: 0.9939 - val_loss: 0.0477 - val_accuracy: 0.9915\n",
      "Epoch 79/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0372 - accuracy: 0.9905 - val_loss: 0.0359 - val_accuracy: 0.9930\n",
      "Epoch 80/200\n",
      "67/67 [==============================] - 13s 190ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.0534 - val_accuracy: 0.9920\n",
      "Epoch 81/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.0354 - val_accuracy: 0.9944\n",
      "Epoch 82/200\n",
      "67/67 [==============================] - 12s 186ms/step - loss: 0.0429 - accuracy: 0.9899 - val_loss: 0.0498 - val_accuracy: 0.9911\n",
      "Epoch 83/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0241 - accuracy: 0.9944 - val_loss: 0.0368 - val_accuracy: 0.9920\n",
      "Epoch 84/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0362 - accuracy: 0.9914 - val_loss: 0.0398 - val_accuracy: 0.9925\n",
      "Epoch 85/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0287 - accuracy: 0.9919 - val_loss: 0.0584 - val_accuracy: 0.9897\n",
      "Epoch 86/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0293 - accuracy: 0.9924 - val_loss: 0.0515 - val_accuracy: 0.9897\n",
      "Epoch 87/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0298 - accuracy: 0.9933 - val_loss: 0.0449 - val_accuracy: 0.9920\n",
      "Epoch 88/200\n",
      "67/67 [==============================] - 12s 182ms/step - loss: 0.0363 - accuracy: 0.9919 - val_loss: 0.0468 - val_accuracy: 0.9911\n",
      "Epoch 89/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0273 - accuracy: 0.9933 - val_loss: 0.0297 - val_accuracy: 0.9944\n",
      "Epoch 90/200\n",
      "67/67 [==============================] - 14s 209ms/step - loss: 0.0332 - accuracy: 0.9919 - val_loss: 0.0429 - val_accuracy: 0.9915\n",
      "Epoch 91/200\n",
      "67/67 [==============================] - 13s 197ms/step - loss: 0.0256 - accuracy: 0.9941 - val_loss: 0.0391 - val_accuracy: 0.9915\n",
      "Epoch 92/200\n",
      "67/67 [==============================] - 13s 188ms/step - loss: 0.0299 - accuracy: 0.9932 - val_loss: 0.0445 - val_accuracy: 0.9920\n",
      "Epoch 93/200\n",
      "67/67 [==============================] - 13s 191ms/step - loss: 0.0319 - accuracy: 0.9925 - val_loss: 0.0468 - val_accuracy: 0.9930\n",
      "Epoch 94/200\n",
      "67/67 [==============================] - 13s 187ms/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 0.0383 - val_accuracy: 0.9934\n",
      "Epoch 95/200\n",
      "67/67 [==============================] - 15s 222ms/step - loss: 0.0343 - accuracy: 0.9914 - val_loss: 0.0436 - val_accuracy: 0.9911\n",
      "Epoch 96/200\n",
      "67/67 [==============================] - 13s 188ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 0.0517 - val_accuracy: 0.9925\n",
      "Epoch 97/200\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.0439 - val_accuracy: 0.9930\n",
      "Epoch 98/200\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 99/200\n",
      "67/67 [==============================] - 13s 187ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.0627 - val_accuracy: 0.9925\n",
      "Epoch 100/200\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 0.0336 - accuracy: 0.9928 - val_loss: 0.0339 - val_accuracy: 0.9944\n",
      "Epoch 101/200\n",
      "67/67 [==============================] - 13s 193ms/step - loss: 0.0286 - accuracy: 0.9917 - val_loss: 0.0437 - val_accuracy: 0.9911\n",
      "Epoch 102/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0239 - accuracy: 0.9951 - val_loss: 0.0278 - val_accuracy: 0.9948\n",
      "Epoch 103/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.0319 - val_accuracy: 0.9948\n",
      "Epoch 104/200\n",
      "67/67 [==============================] - 13s 193ms/step - loss: 0.0295 - accuracy: 0.9927 - val_loss: 0.0331 - val_accuracy: 0.9925\n",
      "Epoch 105/200\n",
      "67/67 [==============================] - 13s 193ms/step - loss: 0.0300 - accuracy: 0.9945 - val_loss: 0.0298 - val_accuracy: 0.9934\n",
      "Epoch 106/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0202 - accuracy: 0.9961 - val_loss: 0.0322 - val_accuracy: 0.9948\n",
      "Epoch 107/200\n",
      "67/67 [==============================] - 12s 186ms/step - loss: 0.0256 - accuracy: 0.9937 - val_loss: 0.0382 - val_accuracy: 0.9920\n",
      "Epoch 108/200\n",
      "67/67 [==============================] - 13s 188ms/step - loss: 0.0205 - accuracy: 0.9955 - val_loss: 0.0367 - val_accuracy: 0.9939\n",
      "Epoch 109/200\n",
      "67/67 [==============================] - 13s 187ms/step - loss: 0.0199 - accuracy: 0.9953 - val_loss: 0.0429 - val_accuracy: 0.9934\n",
      "Epoch 110/200\n",
      "67/67 [==============================] - 12s 186ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.0428 - val_accuracy: 0.9944\n",
      "Epoch 111/200\n",
      "67/67 [==============================] - 13s 187ms/step - loss: 0.0171 - accuracy: 0.9959 - val_loss: 0.0605 - val_accuracy: 0.9925\n",
      "Epoch 112/200\n",
      "67/67 [==============================] - 13s 188ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.0452 - val_accuracy: 0.9934\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 13s 199ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.0251 - val_accuracy: 0.9958\n",
      "Epoch 114/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0312 - val_accuracy: 0.9962\n",
      "Epoch 115/200\n",
      "67/67 [==============================] - 13s 189ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.0303 - val_accuracy: 0.9948\n",
      "Epoch 116/200\n",
      "67/67 [==============================] - 12s 178ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.0317 - val_accuracy: 0.9953\n",
      "Epoch 117/200\n",
      "67/67 [==============================] - 12s 175ms/step - loss: 0.0311 - accuracy: 0.9926 - val_loss: 0.0278 - val_accuracy: 0.9958\n",
      "Epoch 118/200\n",
      "67/67 [==============================] - 12s 177ms/step - loss: 0.0221 - accuracy: 0.9951 - val_loss: 0.0329 - val_accuracy: 0.9939\n",
      "Epoch 119/200\n",
      "67/67 [==============================] - 12s 177ms/step - loss: 0.0258 - accuracy: 0.9952 - val_loss: 0.0438 - val_accuracy: 0.9944\n",
      "Epoch 120/200\n",
      "67/67 [==============================] - 12s 179ms/step - loss: 0.0274 - accuracy: 0.9946 - val_loss: 0.0394 - val_accuracy: 0.9925\n",
      "Epoch 121/200\n",
      "67/67 [==============================] - 12s 176ms/step - loss: 0.0250 - accuracy: 0.9947 - val_loss: 0.0477 - val_accuracy: 0.9925\n",
      "Epoch 122/200\n",
      "67/67 [==============================] - 13s 187ms/step - loss: 0.0201 - accuracy: 0.9951 - val_loss: 0.0344 - val_accuracy: 0.9948\n",
      "Epoch 123/200\n",
      "67/67 [==============================] - 12s 178ms/step - loss: 0.0233 - accuracy: 0.9941 - val_loss: 0.0691 - val_accuracy: 0.9906\n",
      "Epoch 124/200\n",
      "67/67 [==============================] - 12s 177ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 0.0481 - val_accuracy: 0.9897\n",
      "Epoch 125/200\n",
      "67/67 [==============================] - 12s 181ms/step - loss: 0.0274 - accuracy: 0.9932 - val_loss: 0.0353 - val_accuracy: 0.9953\n",
      "Epoch 126/200\n",
      "67/67 [==============================] - 12s 178ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.0434 - val_accuracy: 0.9944\n",
      "Epoch 127/200\n",
      "67/67 [==============================] - 12s 179ms/step - loss: 0.0197 - accuracy: 0.9948 - val_loss: 0.0526 - val_accuracy: 0.9944\n",
      "Epoch 128/200\n",
      "67/67 [==============================] - 12s 181ms/step - loss: 0.0349 - accuracy: 0.9917 - val_loss: 0.0531 - val_accuracy: 0.9920\n",
      "Epoch 129/200\n",
      "67/67 [==============================] - 12s 179ms/step - loss: 0.0301 - accuracy: 0.9934 - val_loss: 0.0561 - val_accuracy: 0.9920\n",
      "Epoch 130/200\n",
      "67/67 [==============================] - 12s 180ms/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 0.0513 - val_accuracy: 0.9930\n",
      "Epoch 131/200\n",
      "67/67 [==============================] - 12s 179ms/step - loss: 0.0370 - accuracy: 0.9912 - val_loss: 0.0533 - val_accuracy: 0.9930\n",
      "Epoch 132/200\n",
      "67/67 [==============================] - 12s 180ms/step - loss: 0.0221 - accuracy: 0.9950 - val_loss: 0.0383 - val_accuracy: 0.9934\n",
      "Epoch 133/200\n",
      "67/67 [==============================] - 12s 180ms/step - loss: 0.0251 - accuracy: 0.9947 - val_loss: 0.0553 - val_accuracy: 0.9915\n",
      "Epoch 134/200\n",
      "67/67 [==============================] - 12s 179ms/step - loss: 0.0364 - accuracy: 0.9920 - val_loss: 0.0461 - val_accuracy: 0.9911\n",
      "Epoch 135/200\n",
      "67/67 [==============================] - 12s 180ms/step - loss: 0.0269 - accuracy: 0.9942 - val_loss: 0.0301 - val_accuracy: 0.9939\n",
      "Epoch 136/200\n",
      "67/67 [==============================] - 12s 180ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0357 - val_accuracy: 0.9944\n",
      "Epoch 137/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0168 - accuracy: 0.9961 - val_loss: 0.0668 - val_accuracy: 0.9892\n",
      "Epoch 138/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0253 - accuracy: 0.9941 - val_loss: 0.0520 - val_accuracy: 0.9915\n",
      "Epoch 139/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0254 - accuracy: 0.9947 - val_loss: 0.0369 - val_accuracy: 0.9930\n",
      "Epoch 140/200\n",
      "67/67 [==============================] - 14s 206ms/step - loss: 0.0165 - accuracy: 0.9964 - val_loss: 0.0486 - val_accuracy: 0.9925\n",
      "Epoch 141/200\n",
      "67/67 [==============================] - 13s 200ms/step - loss: 0.0191 - accuracy: 0.9948 - val_loss: 0.0721 - val_accuracy: 0.9906\n",
      "Epoch 142/200\n",
      "67/67 [==============================] - 13s 201ms/step - loss: 0.0198 - accuracy: 0.9953 - val_loss: 0.0523 - val_accuracy: 0.9934\n",
      "Epoch 143/200\n",
      "67/67 [==============================] - 13s 187ms/step - loss: 0.0251 - accuracy: 0.9935 - val_loss: 0.0418 - val_accuracy: 0.9930\n",
      "Epoch 144/200\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 0.0334 - val_accuracy: 0.9944\n",
      "Epoch 145/200\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 0.0260 - accuracy: 0.9942 - val_loss: 0.0397 - val_accuracy: 0.9925\n",
      "Epoch 146/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0283 - accuracy: 0.9941 - val_loss: 0.0676 - val_accuracy: 0.9915\n",
      "Epoch 147/200\n",
      "67/67 [==============================] - 13s 187ms/step - loss: 0.0185 - accuracy: 0.9962 - val_loss: 0.0405 - val_accuracy: 0.9944\n",
      "Epoch 148/200\n",
      "67/67 [==============================] - 12s 183ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.0744 - val_accuracy: 0.9892\n",
      "Epoch 149/200\n",
      "67/67 [==============================] - 13s 188ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.0393 - val_accuracy: 0.9944\n",
      "Epoch 150/200\n",
      "67/67 [==============================] - 13s 196ms/step - loss: 0.0177 - accuracy: 0.9967 - val_loss: 0.0521 - val_accuracy: 0.9920\n",
      "Epoch 151/200\n",
      "67/67 [==============================] - 14s 209ms/step - loss: 0.0283 - accuracy: 0.9940 - val_loss: 0.0389 - val_accuracy: 0.9934\n",
      "Epoch 152/200\n",
      "67/67 [==============================] - 15s 221ms/step - loss: 0.0211 - accuracy: 0.9952 - val_loss: 0.0363 - val_accuracy: 0.9939\n",
      "Epoch 153/200\n",
      "67/67 [==============================] - 15s 222ms/step - loss: 0.0329 - accuracy: 0.9931 - val_loss: 0.0383 - val_accuracy: 0.9920\n",
      "Epoch 154/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0197 - accuracy: 0.9953 - val_loss: 0.0404 - val_accuracy: 0.9930\n",
      "Epoch 155/200\n",
      "67/67 [==============================] - 13s 196ms/step - loss: 0.0206 - accuracy: 0.9948 - val_loss: 0.0328 - val_accuracy: 0.9948\n",
      "Epoch 156/200\n",
      "67/67 [==============================] - 13s 196ms/step - loss: 0.0214 - accuracy: 0.9951 - val_loss: 0.0406 - val_accuracy: 0.9934\n",
      "Epoch 157/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.0421 - val_accuracy: 0.9939\n",
      "Epoch 158/200\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 0.0285 - accuracy: 0.9938 - val_loss: 0.0637 - val_accuracy: 0.9897\n",
      "Epoch 159/200\n",
      "67/67 [==============================] - 13s 198ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.0552 - val_accuracy: 0.9920\n",
      "Epoch 160/200\n",
      "67/67 [==============================] - 12s 186ms/step - loss: 0.0180 - accuracy: 0.9961 - val_loss: 0.0322 - val_accuracy: 0.9948\n",
      "Epoch 161/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.0381 - val_accuracy: 0.9948\n",
      "Epoch 162/200\n",
      "67/67 [==============================] - 12s 184ms/step - loss: 0.0140 - accuracy: 0.9974 - val_loss: 0.0302 - val_accuracy: 0.9944\n",
      "Epoch 163/200\n",
      "67/67 [==============================] - 13s 191ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.0456 - val_accuracy: 0.9920\n",
      "Epoch 164/200\n",
      "67/67 [==============================] - 12s 185ms/step - loss: 0.0168 - accuracy: 0.9960 - val_loss: 0.0347 - val_accuracy: 0.9948\n",
      "Epoch 165/200\n",
      "67/67 [==============================] - 13s 189ms/step - loss: 0.0236 - accuracy: 0.9959 - val_loss: 0.0263 - val_accuracy: 0.9925\n",
      "Epoch 166/200\n",
      "67/67 [==============================] - 13s 187ms/step - loss: 0.0166 - accuracy: 0.9960 - val_loss: 0.0251 - val_accuracy: 0.9953\n",
      "Epoch 167/200\n",
      "67/67 [==============================] - 14s 211ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.0407 - val_accuracy: 0.9915\n",
      "Epoch 168/200\n",
      "67/67 [==============================] - 14s 216ms/step - loss: 0.0173 - accuracy: 0.9968 - val_loss: 0.0366 - val_accuracy: 0.9930\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 13s 188ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 0.0435 - val_accuracy: 0.9953\n",
      "Epoch 170/200\n",
      "67/67 [==============================] - 13s 190ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.0400 - val_accuracy: 0.9934\n",
      "Epoch 171/200\n",
      "67/67 [==============================] - 13s 188ms/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 0.0293 - val_accuracy: 0.9953\n",
      "Epoch 172/200\n",
      "67/67 [==============================] - 13s 195ms/step - loss: 0.0151 - accuracy: 0.9977 - val_loss: 0.0465 - val_accuracy: 0.9934\n",
      "Epoch 173/200\n",
      "67/67 [==============================] - 13s 193ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.0514 - val_accuracy: 0.9934\n",
      "Epoch 174/200\n",
      "67/67 [==============================] - 14s 209ms/step - loss: 0.0211 - accuracy: 0.9953 - val_loss: 0.0502 - val_accuracy: 0.9925\n",
      "Epoch 175/200\n",
      "67/67 [==============================] - 15s 223ms/step - loss: 0.0216 - accuracy: 0.9946 - val_loss: 0.0398 - val_accuracy: 0.9934\n",
      "Epoch 176/200\n",
      "67/67 [==============================] - 14s 204ms/step - loss: 0.0200 - accuracy: 0.9961 - val_loss: 0.0419 - val_accuracy: 0.9925\n",
      "Epoch 177/200\n",
      "67/67 [==============================] - 18s 275ms/step - loss: 0.0260 - accuracy: 0.9940 - val_loss: 0.0455 - val_accuracy: 0.9944\n",
      "Epoch 178/200\n",
      "67/67 [==============================] - 16s 242ms/step - loss: 0.0298 - accuracy: 0.9930 - val_loss: 0.0541 - val_accuracy: 0.9934\n",
      "Epoch 179/200\n",
      "67/67 [==============================] - 16s 245ms/step - loss: 0.0253 - accuracy: 0.9945 - val_loss: 0.0784 - val_accuracy: 0.9906\n",
      "Epoch 180/200\n",
      "67/67 [==============================] - 15s 217ms/step - loss: 0.0331 - accuracy: 0.9921 - val_loss: 0.0673 - val_accuracy: 0.9897\n",
      "Epoch 181/200\n",
      "67/67 [==============================] - 14s 213ms/step - loss: 0.0331 - accuracy: 0.9933 - val_loss: 0.0414 - val_accuracy: 0.9930\n",
      "Epoch 182/200\n",
      "67/67 [==============================] - 16s 244ms/step - loss: 0.0284 - accuracy: 0.9939 - val_loss: 0.0319 - val_accuracy: 0.9948\n",
      "Epoch 183/200\n",
      "67/67 [==============================] - 17s 259ms/step - loss: 0.0352 - accuracy: 0.9925 - val_loss: 0.0416 - val_accuracy: 0.9934\n",
      "Epoch 184/200\n",
      "67/67 [==============================] - 17s 247ms/step - loss: 0.0224 - accuracy: 0.9945 - val_loss: 0.0590 - val_accuracy: 0.9934\n",
      "Epoch 185/200\n",
      "67/67 [==============================] - 17s 255ms/step - loss: 0.0305 - accuracy: 0.9935 - val_loss: 0.0560 - val_accuracy: 0.9925\n",
      "Epoch 186/200\n",
      "67/67 [==============================] - 15s 226ms/step - loss: 0.0298 - accuracy: 0.9942 - val_loss: 0.0551 - val_accuracy: 0.9911\n",
      "Epoch 187/200\n",
      "67/67 [==============================] - 14s 206ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.0415 - val_accuracy: 0.9948\n",
      "Epoch 188/200\n",
      "67/67 [==============================] - 18s 267ms/step - loss: 0.0181 - accuracy: 0.9973 - val_loss: 0.0563 - val_accuracy: 0.9920\n",
      "Epoch 189/200\n",
      "67/67 [==============================] - 18s 272ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.0762 - val_accuracy: 0.9930\n",
      "Epoch 190/200\n",
      "67/67 [==============================] - 18s 263ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.0563 - val_accuracy: 0.9939\n",
      "Epoch 191/200\n",
      "67/67 [==============================] - 17s 258ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0435 - val_accuracy: 0.9939\n",
      "Epoch 192/200\n",
      "67/67 [==============================] - 13s 191ms/step - loss: 0.0290 - accuracy: 0.9938 - val_loss: 0.0726 - val_accuracy: 0.9911\n",
      "Epoch 193/200\n",
      "67/67 [==============================] - 13s 194ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 0.0714 - val_accuracy: 0.9897\n",
      "Epoch 194/200\n",
      "67/67 [==============================] - 13s 199ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 0.0768 - val_accuracy: 0.9915\n",
      "Epoch 195/200\n",
      "67/67 [==============================] - 14s 208ms/step - loss: 0.0114 - accuracy: 0.9973 - val_loss: 0.0418 - val_accuracy: 0.9944\n",
      "Epoch 196/200\n",
      "67/67 [==============================] - 18s 273ms/step - loss: 0.0267 - accuracy: 0.9951 - val_loss: 0.0694 - val_accuracy: 0.9915\n",
      "Epoch 197/200\n",
      "67/67 [==============================] - 23s 340ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.0525 - val_accuracy: 0.9911\n",
      "Epoch 198/200\n",
      "67/67 [==============================] - 24s 362ms/step - loss: 0.0288 - accuracy: 0.9939 - val_loss: 0.0413 - val_accuracy: 0.9930\n",
      "Epoch 199/200\n",
      "67/67 [==============================] - 15s 230ms/step - loss: 0.0230 - accuracy: 0.9947 - val_loss: 0.0480 - val_accuracy: 0.9944\n",
      "Epoch 200/200\n",
      "67/67 [==============================] - 16s 237ms/step - loss: 0.0275 - accuracy: 0.9955 - val_loss: 0.0472 - val_accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x147c5f668>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(17, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the trained weights\n",
    "model.load_weights(\"weight.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    video_name\n",
       "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi\n",
       "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi\n",
       "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi\n",
       "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi\n",
       "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the test list\n",
    "f = open(\"testlist01.txt\", \"r\")\n",
    "temp = f.read()\n",
    "videos = temp.split('\\n')\n",
    "\n",
    "# creating the dataframe\n",
    "test = pd.DataFrame()\n",
    "test['video_name'] = videos\n",
    "test = test[:-1]\n",
    "test_videos = test['video_name']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the tags\n",
    "train = pd.read_csv('UCF/train_new.csv')\n",
    "y = train['class']\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos = test_videos[:659]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 659/659 [18:14<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "# creating two lists to store predicted and actual tags\n",
    "predict = []\n",
    "actual = []\n",
    "\n",
    "# for loop to extract frames from each test video\n",
    "for i in tqdm(range(test_videos.shape[0])):\n",
    "    count = 0\n",
    "    videoFile = test_videos[i]\n",
    "    cap = cv2.VideoCapture('UCF/'+videoFile.split(' ')[0].split('/')[1])   # capturing the video from the given path\n",
    "    frameRate = cap.get(5) #frame rate\n",
    "    x=1\n",
    "    # removing all other files from the temp folder\n",
    "    files = glob('temp/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if (frameId % math.floor(frameRate) == 0):\n",
    "            # storing the frames of this particular video in temp folder\n",
    "            filename ='temp/' + \"_frame%d.jpg\"%count\n",
    "            count+=1\n",
    "            cv2.imwrite(filename, frame)\n",
    "    cap.release()\n",
    "    \n",
    "    # reading all the frames from temp folder\n",
    "    images = glob(\"temp/*.jpg\")\n",
    "    \n",
    "    prediction_images = []\n",
    "    for i in range(len(images)):\n",
    "        img = image.load_img(images[i], target_size=(224,224,3))\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/255\n",
    "        prediction_images.append(img)\n",
    "        \n",
    "    # converting all the frames for a test video into numpy array\n",
    "    prediction_images = np.array(prediction_images)\n",
    "    # extracting features using pre-trained model\n",
    "    prediction_images = base_model.predict(prediction_images)\n",
    "    # converting features in one dimensional array\n",
    "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
    "    # predicting tags for each array\n",
    "    prediction = model.predict_classes(prediction_images)\n",
    "    # appending the mode of predictions in predict list to assign the tag to the video\n",
    "    predict.append(y.columns.values[s.mode(prediction)[0][0]])\n",
    "    # appending the actual tag of the video\n",
    "    actual.append(videoFile.split('/')[1].split('_')[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.14112291350531"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the accuracy of the predicted tags\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predict, actual)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
